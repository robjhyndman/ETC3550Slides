---
title: "ETC3550/ETC5550 Applied&nbsp;forecasting"
author: "Ch10. Dynamic regression models"
institute: "OTexts.org/fpp3/"
pdf-engine: pdflatex
fig-width: 7.5
fig-height: 3.5
format:
  beamer:
    theme: monash
    aspectratio: 169
    fontsize: 14pt
    section-titles: false
    knitr:
      opts_chunk:
        dev: "cairo_pdf"
include-in-header: header.tex
execute:
  echo: false
  message: false
  warning: false
---


```{r setup, include=FALSE}
source("setup.R")
library(readr)

vic_elec_daily <- vic_elec |>
  filter(year(Time) == 2014) |>
  index_by(Date = date(Time)) |>
  summarise(
    Demand = sum(Demand) / 1e3,
    Temperature = max(Temperature),
    Holiday = any(Holiday)
  ) |>
  mutate(Day_Type = case_when(
    Holiday ~ "Holiday",
    wday(Date) %in% 2:6 ~ "Weekday",
    TRUE ~ "Weekend"
  ))
```

# Regression with ARIMA errors

## Regression with ARIMA errors

\begin{block}{Regression models}\vspace*{-0.2cm}
\[
  y_t = \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \varepsilon_t,
\]
\end{block}\vspace*{-0.3cm}

  * $y_t$ modeled as function of $k$ explanatory variables
$x_{1,t},\dots,x_{k,t}$.
  * In regression, we assume that $\varepsilon_t$ is WN.
  * Now we want to allow $\varepsilon_t$ to be autocorrelated.
\vspace*{0.3cm}
\pause
\begin{alertblock}{Example: ARIMA(1,1,1) errors}\vspace*{-0.2cm}
\begin{align*}
  y_t &= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\\
      & (1-\phi_1B)(1-B)\eta_t = (1+\theta_1B)\varepsilon_t,
\end{align*}
\end{alertblock}
\rightline{where $\varepsilon_t$ is white noise.}

## Residuals and errors

\begin{alertblock}{Example: $\eta_t$ = ARIMA(1,1,1)}\vspace*{-0.2cm}
\begin{align*}
  y_t &= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\\
      & (1-\phi_1B)(1-B)\eta_t = (1+\theta_1B)\varepsilon_t,
\end{align*}\end{alertblock}\pause

  * Be careful in distinguishing $\eta_t$ from $\varepsilon_t$.
  * Only the errors $\varepsilon_t$ are assumed to be white noise.
  * In ordinary regression, $\eta_t$ is assumed to be white noise and so $\eta_t = \varepsilon_t$.

## Estimation

If we minimize $\sum \eta_t^2$ (by using ordinary regression):

  1. Estimated coefficients $\hat{\beta}_0,\dots,\hat{\beta}_k$ are no longer optimal as some information ignored;
  2. Statistical tests associated with the model (e.g., t-tests on the coefficients) are incorrect.
  3. $p$-values for coefficients usually too small (``spurious regression'').
  4. AIC of fitted models misleading.

\pause

 * Minimizing $\sum \varepsilon_t^2$ avoids these problems.
 * Maximizing likelihood similar to minimizing $\sum \varepsilon_t^2$.

## Regression with ARIMA errors

\begin{block}{Model with ARIMA(1,1,1) errors}\vspace*{-0.2cm}
\begin{align*}
  y_t &= \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t,\\
      & (1-\phi_1B)(1-B)\eta_t = (1+\theta_1B)\varepsilon_t,
\end{align*}
\end{block}\pause

\begin{block}{Equivalent to model with ARIMA(1,0,1) errors}\vspace*{-0.2cm}
\begin{align*}
  y'_t &= \beta_1 x'_{1,t} + \dots + \beta_k x'_{k,t} + \eta'_t,\\
       & (1-\phi_1B)\eta'_t = (1+\theta_1B)\varepsilon_t,
\end{align*}
\end{block}
where $y'_t=y_t-y_{t-1}$, $x'_{t,i}=x_{t,i}-x_{t-1,i}$ and  $\eta'_t=\eta_t-\eta_{t-1}$.

## Regression with ARIMA errors
\fontsize{14}{15}\sf

Any regression with an ARIMA error can be rewritten as a regression with an ARMA error by differencing all variables with the same differencing operator as in the ARIMA model.\pause

\begin{block}{Original data}\vspace*{-0.2cm}
\begin{align*}
  y_t & = \beta_0 + \beta_1 x_{1,t} + \dots + \beta_k x_{k,t} + \eta_t\\
  \mbox{where}\quad
      & \phi(B)(1-B)^d\eta_t = \theta(B)\varepsilon_t
\end{align*}
\end{block}\pause\vspace*{-0.1cm}
\begin{block}{After differencing all variables}\vspace*{-0.2cm}
$$
  y'_t  = \beta_1 x'_{1,t} + \dots + \beta_k x'_{k,t} + \eta'_t.
$$
where $\phi(B)\eta'_t = \theta(B)\varepsilon_t$,\vspace*{0.1cm}

$y_t' = (1-B)^dy_t$,\quad $x_{i,t}' = (1-B)^dx_{i,t}$,\quad and $\eta_t' = (1-B)^d \eta_t$
\end{block}

## Regression with ARIMA errors

  * In R, we can specify an ARIMA($p,d,q$) for the errors, and $d$ levels of differencing will be applied to all variables ($y, x_{1,t},\dots,x_{k,t}$) during estimation.
  * Check that $\varepsilon_t$ series looks like white noise.
  * AICc can be calculated for final model.
  * Repeat procedure for all subsets of predictors to be considered, and select model with lowest AICc value.

## US personal consumption and income

```{r usconsump, fig.height=6, fig.width=9, echo=FALSE, out.height="92%"}
us_change |>
  gather(key = "variable", value = "value") |>
  ggplot(aes(y = value, x = Quarter, group = variable, colour = variable)) +
  geom_line() +
  facet_grid(variable ~ ., scales = "free_y") +
  labs(y = "", title = "Quarterly changes in US consumption and personal income") +
  guides(colour = "none")
```

## US personal consumption and income
\fontsize{11}{12}\sf

```{r usconsump2, echo=TRUE, fig.height=3}
fit <- us_change |> model(ARIMA(Consumption ~ Income))
report(fit)
```

\pause\begin{alertblock}{}
Write down the equations for the fitted model.
\end{alertblock}

## US personal consumption and income

```{r , echo=TRUE, fig.height=3}
residuals(fit, type = "regression") |>
  gg_tsdisplay(.resid, plot_type = "partial") +
  labs(title = "Regression errors")
```

## US personal consumption and income

```{r , echo=TRUE, fig.height=3}
residuals(fit, type = "innovation") |>
  gg_tsdisplay(.resid, plot_type = "partial") +
  labs(title = "ARIMA errors")
```

## US personal consumption and income
\fontsize{11}{12}\sf

```{r , echo=TRUE, fig.height=3.7}
augment(fit) |>
  features(.innov, ljung_box, dof = 5, lag = 12)
```

## US personal consumption and income

```{r usconsump3, echo=TRUE, fig.height=2.4}
us_change_future <- new_data(us_change, 8) |>
  mutate(Income = mean(us_change$Income))
forecast(fit, new_data = us_change_future) |>
  autoplot(us_change) +
  labs(
    x = "Year", y = "Percentage change",
    title = "Forecasts from regression with ARIMA(1,0,2) errors"
  )
```

## Forecasting

  * To forecast a regression model with ARIMA errors, we need to forecast the
regression part of the model and the ARIMA part of the model and combine the
results.
  * Some predictors are known into the future (e.g., time, dummies).
  * Separate forecasting models may be needed for other predictors.
  * Forecast intervals ignore the uncertainty in forecasting the predictors.

## Daily electricity demand

```{r, echo=TRUE}
vic_elec_daily |>
  ggplot(aes(x = Temperature, y = Demand, colour = Day_Type)) +
  geom_point() +
  labs(x = "Maximum temperature", y = "Electricity demand (GW)")
```

## Daily electricity demand

```{r, echo=TRUE}
vic_elec_daily |>
  pivot_longer(c(Demand, Temperature)) |>
  ggplot(aes(x = Date, y = value)) +
  geom_line() +
  facet_grid(name ~ ., scales = "free_y") +
  ylab("")
```

## Daily electricity demand
\fontsize{9}{9.5}\sf

```{r, echo=TRUE}
fit <- vic_elec_daily |>
  model(ARIMA(Demand ~ Temperature + I(Temperature^2) +
    (Day_Type == "Weekday")))
report(fit)
```

## Daily electricity demand

```{r, echo=TRUE}
gg_tsresiduals(fit)
```

## Daily electricity demand
\fontsize{10}{11}\sf

```{r, echo=TRUE}
augment(fit) |>
  features(.resid, ljung_box, dof = 9, lag = 14)
```

## Daily electricity demand
\fontsize{10}{13}\sf

```{r, echo=TRUE}
# Forecast one day ahead
vic_next_day <- new_data(vic_elec_daily, 1) |>
  mutate(Temperature = 26, Day_Type = "Holiday")
forecast(fit, vic_next_day)
```

## Daily electricity demand
\fontsize{10}{11}\sf
```{r, echo=TRUE}
vic_elec_future <- new_data(vic_elec_daily, 14) |>
  mutate(
    Temperature = 26,
    Holiday = c(TRUE, rep(FALSE, 13)),
    Day_Type = case_when(
      Holiday ~ "Holiday",
      wday(Date) %in% 2:6 ~ "Weekday",
      TRUE ~ "Weekend"
    )
  )
```

## Daily electricity demand

```{r, echo = TRUE}
forecast(fit, new_data = vic_elec_future) |>
  autoplot(vic_elec_daily) + labs(y = "GW")
```

# Stochastic and deterministic trends

## Stochastic \& deterministic trends

\begin{block}{Deterministic trend}
\[ y_t = \beta_0 + \beta_1 t + \eta_t \]
where $\eta_t$ is ARMA process.\pause
\end{block}

\begin{block}{Stochastic trend}
\[ y_t = \beta_0 + \beta_1 t + \eta_t \]
where $\eta_t$ is ARIMA process with $d\ge1$.\pause

Difference both sides until $\eta_t$ is stationary:
\[ y'_t = \beta_1 + \eta'_t \]
where $\eta'_t$ is ARMA process.
\end{block}

## Air transport passengers Australia

```{r}
aus_airpassengers |>
  autoplot(Passengers) +
  labs(
    y = "Passengers (millions)",
    title = "Total air passengers"
  )
```

## Air transport passengers Australia

**Deterministic trend**

\fontsize{10}{10}\sf

```{r, echo=TRUE}
fit_deterministic <- aus_airpassengers |>
  model(ARIMA(Passengers ~ 1 + trend() + pdq(d = 0)))
report(fit_deterministic)
```

```{r austaparams, echo=FALSE, dependson='deterministictrend'}
coef <- rlang::set_names(tidy(fit_deterministic)$estimate, tidy(fit_deterministic)$term)
phi1 <- coef["ar1"]
intercept <- coef["intercept"]
slope <- coef["trend()"]
sigma2 <- glance(fit_deterministic)$sigma2
```

\only<2>{\begin{textblock}{5}(9,4.5)
\begin{block}{}\vspace*{-0.2cm}\fontsize{12}{13}\sf
\begin{align*}
  y_t &= `r sprintf("%.3f", intercept)` + `r sprintf("%.3f", slope)` t + \eta_t \\
  \eta_t &= `r sprintf("%.3f", phi1)` \eta_{t-1}  + \varepsilon_t\\
  \varepsilon_t &\sim \text{NID}(0,`r sprintf("%.3f", sigma2)`).
\end{align*}
\end{block}
\end{textblock}}

\vspace*{10cm}

## Air transport passengers Australia

**Stochastic trend**

\fontsize{10}{10}\sf

```{r, echo=TRUE}
fit_stochastic <- aus_airpassengers |>
  model(ARIMA(Passengers ~ pdq(d = 1)))
report(fit_stochastic)
```

```{r austaparams2, echo=FALSE, dependson='stochastictrend'}
coef <- rlang::set_names(tidy(fit_stochastic)$estimate, tidy(fit_stochastic)$term)
drift <- coef["constant"]
sigma2 <- glance(fit_stochastic)$sigma2
```

\only<2>{\begin{textblock}{5}(9,4.5)
\begin{block}{}\vspace*{-0.2cm}\fontsize{12}{13}\sf
\begin{align*}
  y_t-y_{t-1} &= `r sprintf("%.3f", drift)` + \varepsilon_t,\\
  y_t &= y_0 + `r sprintf("%.3f", drift)` t + \eta_t \\
  \eta_t &= \eta_{t-1} + \varepsilon_{t}\\
  \varepsilon_t &\sim \text{NID}(0,`r sprintf("%.3f", sigma2)`).
\end{align*}
\end{block}
\end{textblock}}

\vspace*{10cm}

## Air transport passengers Australia

```{r, fig.height=2.2}
aus_airpassengers |>
  autoplot(Passengers) +
  autolayer(fit_stochastic |> forecast(h = 20),
    colour = "#0072B2", level = 95
  ) +
  autolayer(fit_deterministic |> forecast(h = 20),
    colour = "#D55E00", alpha = 0.65, level = 95
  ) +
  labs(
    y = "Air passengers (millions)",
    title = "Forecasts from trend models"
  )
```

## Forecasting with trend

  * Point forecasts are almost identical, but prediction intervals differ.
  * Stochastic trends have much wider prediction intervals because the errors are non-stationary.
  * Be careful of forecasting with deterministic trends too far ahead.

# Dynamic harmonic regression

## Dynamic harmonic regression
\fontsize{14}{15}\sf

\alert{Combine Fourier terms with ARIMA errors}

### Advantages
   * it allows any length seasonality;
   * for data with more than one seasonal period, you can include Fourier terms of different frequencies;
   * the seasonal pattern is smooth for small values of $K$ (but more wiggly seasonality can be handled by increasing $K$);
   * the short-term dynamics are easily handled with a simple ARMA error.

### Disadvantages
 * seasonality is assumed to be fixed

## Eating-out expenditure

```{r cafe, echo=TRUE, fig.height=2.6}
aus_cafe <- aus_retail |>
  filter(
    Industry == "Cafes, restaurants and takeaway food services",
    year(Month) %in% 2004:2018
  ) |>
  summarise(Turnover = sum(Turnover))
aus_cafe |> autoplot(Turnover)
```

## Eating-out expenditure

\fontsize{10}{10.5}\sf

```{r cafefit, dependson='cafe', echo=TRUE, results='hide'}
fit <- aus_cafe |> model(
  `K = 1` = ARIMA(log(Turnover) ~ fourier(K = 1) + PDQ(0, 0, 0)),
  `K = 2` = ARIMA(log(Turnover) ~ fourier(K = 2) + PDQ(0, 0, 0)),
  `K = 3` = ARIMA(log(Turnover) ~ fourier(K = 3) + PDQ(0, 0, 0)),
  `K = 4` = ARIMA(log(Turnover) ~ fourier(K = 4) + PDQ(0, 0, 0)),
  `K = 5` = ARIMA(log(Turnover) ~ fourier(K = 5) + PDQ(0, 0, 0)),
  `K = 6` = ARIMA(log(Turnover) ~ fourier(K = 6) + PDQ(0, 0, 0))
)
glance(fit)
```
```{r, echo = FALSE}
glance(fit) |>
  select(.model, sigma2, log_lik, AIC, AICc, BIC) |>
  knitr::kable()
```

## Eating-out expenditure

```{r, echo=FALSE}
cafe_plot <- function(...) {
  fit |>
    select(...) |>
    forecast() |>
    autoplot(aus_cafe) +
    labs(title = sprintf("Log transformed %s, fourier(K = %s)", model_sum(select(fit, ...)[[1]][[1]]), deparse(..1))) +
    geom_label(
      aes(x = yearmonth("2007 Jan"), y = 4250, label = paste0("AICc = ", format(AICc))),
      data = glance(select(fit, ...))
    ) +
    geom_line(aes(y = .fitted), colour = "red", augment(select(fit, ...))) +
    ylim(c(1500, 5100))
}
```

```{r cafe1, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 1)
```

## Eating-out expenditure

```{r cafe2, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 2)
```

## Eating-out expenditure

```{r cafe3, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 3)
```

## Eating-out expenditure

```{r cafe4, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 4)
```

## Eating-out expenditure

```{r cafe5, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 5)
```

## Eating-out expenditure

```{r cafe6, dependson='cafe', fig.height=4, echo=FALSE}
cafe_plot(K = 6)
```

## Example: weekly gasoline products
\fontsize{8}{8}\sf
```{r, echo = FALSE}
options(width = 70)
```

```{r gasmodel, echo=TRUE}
fit <- us_gasoline |>
  model(ARIMA(Barrels ~ fourier(K = 13) + PDQ(0, 0, 0)))
report(fit)
```

## Example: weekly gasoline products

```{r gasf, echo=TRUE, fig.height=3.2}
forecast(fit, h = "3 years") |>
  autoplot(us_gasoline)
```

## 5-minute call centre volume
\fontsize{10}{10}\sf

```{r calls, echo=TRUE, fig.height=4}
(calls <- readr::read_tsv("http://robjhyndman.com/data/callcenter.txt") |>
  rename(time = `...1`) |>
  pivot_longer(-time, names_to = "date", values_to = "volume") |>
  mutate(
    date = as.Date(date, format = "%d/%m/%Y"),
    datetime = as_datetime(date) + time
  ) |>
  as_tsibble(index = datetime))
```

## 5-minute call centre volume

```{r calls-plot, echo=TRUE, fig.height=4}
calls |>
  fill_gaps() |>
  autoplot(volume)
```

## 5-minute call centre volume

```{r calls-season, echo=TRUE, fig.height=3}
calls |>
  fill_gaps() |>
  gg_season(volume, period = "day", alpha = 0.1) +
  guides(colour = FALSE)
```

## 5-minute call centre volume
\fontsize{10}{10}\sf

```{r callsmodel, echo=TRUE}
calls_mdl <- calls |>
  mutate(idx = row_number()) |>
  update_tsibble(index = idx)
fit <- calls_mdl |>
  model(ARIMA(volume ~ fourier(169, K = 10) + pdq(d = 0) + PDQ(0, 0, 0)))
report(fit)
```

## 5-minute call centre volume

```{r callsres, echo=TRUE, fig.height=4}
gg_tsresiduals(fit, lag = 338)
```

## 5-minute call centre volume

```{r callsf, echo=TRUE, fig.height=3.2}
fit |>
  forecast(h = 1690) |>
  autoplot(calls_mdl)
```

## 5-minute call centre volume

```{r callsf2, echo=TRUE, fig.height=3.2}
fit |>
  forecast(h = 1690) |>
  autoplot(filter(calls_mdl, idx > 25000))
```

# Lagged predictors

## Lagged predictors

Sometimes a change in $x_t$ does not affect $y_t$ instantaneously\pause
\begin{block}{}
\begin{itemize}
  \item $y_t=$ sales, $x_t=$ advertising.
  \item $y_t=$ stream flow, $x_t=$ rainfall.
  \item $y_t=$ size of herd, $x_t=$ breeding stock.
\end{itemize}
\end{block}
\pause

  * These are dynamic systems with input ($x_t$) and output $(y_t)$.
  * $x_t$ is often a leading indicator.
  * There can be multiple predictors.

## Lagged predictors

The model include present and past values of predictor:
\begin{block}{}
\centerline{$
y_t = a + \gamma_0x_t + \gamma_1x_{t-1} + \dots + \gamma_kx_{t-k} + \eta_t$}
\end{block}
where $\eta_t$ is an ARIMA process.\pause

**Rewrite model as **
\begin{align*}
y_{t} & = a+ (\gamma_{0} + \gamma_{1} B + \gamma_{2} B^{2} + \dots + \gamma_{k} B^{k}) x_{t} +\eta_t \\
      & = a+ \gamma(B) x_{t} +\eta_t.
\end{align*}\pause\vspace*{-0.9cm}

  * $\gamma(B)$ is called a \textit{transfer function} since it describes how
change in $x_t$ is transferred to $y_t$.
  * $x$ can influence $y$, but $y$ is not allowed to influence $x$.

## Example: Insurance quotes and TV adverts

```{r tvadvert, fig.height=2.5}
insurance |>
  pivot_longer(Quotes:TVadverts) |>
  ggplot(aes(x = Month, y = value)) +
  geom_line() +
  facet_grid(vars(name), scales = "free_y") +
  labs(y = NULL, title = "Insurance advertising and quotations")
```

## Example: Insurance quotes and TV adverts

```{r tvadvertpairs, dependson='tvadvertdata', echo=FALSE}
insurance |>
  mutate(
    lag1 = lag(TVadverts),
    lag2 = lag(lag1)
  ) |>
  as_tibble() |>
  select(-Month) |>
  rename(lag0 = TVadverts) |>
  pivot_longer(-Quotes, names_to = "Lag", values_to = "TV_advert") |>
  ggplot(aes(x = TV_advert, y = Quotes)) +
  geom_point() +
  facet_grid(. ~ Lag) +
  labs(title = "Insurance advertising and quotations")
```

## Example: Insurance quotes and TV adverts

```{r, echo=TRUE}
fit <- insurance |>
  # Restrict data so models use same fitting period
  mutate(Quotes = c(NA, NA, NA, Quotes[4:40])) |>
  # Estimate models
  model(
    ARIMA(Quotes ~ pdq(d = 0) + TVadverts),
    ARIMA(Quotes ~ pdq(d = 0) + TVadverts + lag(TVadverts)),
    ARIMA(Quotes ~ pdq(d = 0) + TVadverts + lag(TVadverts) +
      lag(TVadverts, 2)),
    ARIMA(Quotes ~ pdq(d = 0) + TVadverts + lag(TVadverts) +
      lag(TVadverts, 2) + lag(TVadverts, 3))
  )
```

## Example: Insurance quotes and TV adverts
\fontsize{10}{10}\sf

```{r, echo=TRUE, results = 'hide'}
glance(fit)
```
```{r, echo = FALSE}
glance(fit) |>
  transmute(`Lag order` = 0:3, sigma2, log_lik, AIC, AICc, BIC) |>
  knitr::kable()
```

## Example: Insurance quotes and TV adverts

\fontsize{10}{10}\sf

```{r tvadvertagain, echo=TRUE}
fit_best <- insurance |>
  model(ARIMA(Quotes ~ pdq(d = 0) + TVadverts + lag(TVadverts)))
report(fit_best)
```

\pause
\vspace{-1em}

```{r tvadvertparam, echo=FALSE, dependson="tvadvertagain"}
# Store coefficients
tidy_fit <- tidy(fit_best)
coef <- rlang::set_names(tidy_fit$estimate, tidy_fit$term)
phi1 <- coef["ar1"]
ma1 <- coef["ma1"]
ma2 <- coef["ma2"]
intercept <- coef["intercept"]
gamma0 <- coef["TVadverts"]
gamma1 <- coef["lag(TVadverts)"]
```
\vspace*{0.2cm}

###
\vspace*{-0.2cm}\begin{align*}
  y_t &= `r sprintf("%.3f", intercept)` +
         `r sprintf("%.3f", gamma0)` x_t +
         `r sprintf("%.3f", gamma1)` x_{t-1} + \eta_t,\\
  \eta_t &= `r sprintf("%.3f", phi1)` \eta_{t-1} +
                                     \varepsilon_t +
            `r sprintf("%.3f", ma1)` \varepsilon_{t-1} +
            `r sprintf("%.3f", ma2)` \varepsilon_{t-2},
\end{align*}

## Example: Insurance quotes and TV adverts

```{r, echo=TRUE, fig.height=3}
advert_a <- new_data(insurance, 20) |>
  mutate(TVadverts = 10)
forecast(fit_best, advert_a) |> autoplot(insurance)
```

## Example: Insurance quotes and TV adverts

```{r, echo=TRUE, fig.height=3}
advert_b <- new_data(insurance, 20) |>
  mutate(TVadverts = 8)
forecast(fit_best, advert_b) |> autoplot(insurance)
```

## Example: Insurance quotes and TV adverts

```{r, echo=TRUE, fig.height=3}
advert_c <- new_data(insurance, 20) |>
  mutate(TVadverts = 6)
forecast(fit_best, advert_c) |> autoplot(insurance)
```
